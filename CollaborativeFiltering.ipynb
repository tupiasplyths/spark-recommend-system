{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Start Spark\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql import functions\n",
    "from pyspark import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Project\") \\\n",
    "    .master(\"spark://10.10.28.60:7077\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.local.dir\", \"/tmp/spark-temp\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "    # .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    # .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    \n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Data Preparation**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "movies = spark.read.parquet('hdfs://master5:9000/user/dis/movielens/movies.parquet')\n",
    "ratings = spark.read.parquet('hdfs://master5:9000/user/dis/movielens/ratings.parquet')\n",
    "tags = spark.read.parquet('hdfs://master5:9000/user/dis/movielens/tags.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#Create a temporary view for to access data using SQL-like queries\n",
    "df_movies = movies\n",
    "df_ratings = ratings\n",
    "df_tags = tags\n",
    "df_movies.createOrReplaceTempView(\"movies\")\n",
    "df_ratings.createOrReplaceTempView(\"ratings\")\n",
    "df_tags.createOrReplaceTempView(\"tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#remove 'timestamp' column and turn userID and movieId to integer\n",
    "df_ratings = df_ratings.drop('timestamp')\n",
    "df_ratings = df_ratings.dropna(subset=['userId', 'movieId'])\n",
    "df_ratings = df_ratings.withColumn(\"userId\", df_ratings[\"userId\"].cast(\"int\"))\n",
    "df_ratings = df_ratings.withColumn(\"movieId\", df_ratings[\"movieId\"].cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'hdfs://master5:9000/user/dis/output-4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#Split data\n",
    "(train, test) = df_ratings.randomSplit([0.8, 0.2], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Initialize the ALS (Alternating Least Squares) recommender model\n",
    "alsb = ALS(rank=15, maxIter=15, regParam=0.05, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", \\\n",
    "               coldStartStrategy=\"drop\")\n",
    "# Train the ALS model on the training data\n",
    "alsb_model = alsb.fit(train)\n",
    "\n",
    "# Evaluate the trained ALS model on the test data\n",
    "alsb_predictions = alsb_model.transform(test)\n",
    "#Calculate RMSE and print\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(alsb_predictions) \n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "\n",
    "# save the ALS model\n",
    "alsb_model.save(model_path + 'als')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previously saved ALS model\n",
    "alsn_model = ALSModel.read().load(model_path+ 'als')\n",
    "\n",
    "#Get 5 recommends for user\n",
    "userRecoms = alsn_model.recommendForAllUsers(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the user recommendations to a Parquet file\n",
    "userRecoms.write.mode('overwrite').parquet(model_path + \"recom_als\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved recommendations from the Parquet file\n",
    "recommendation = spark.read.parquet(model_path + \"recom_als\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(user_id):\n",
    "    \"\"\"\n",
    "    Get the top recommended movie IDs for a given user ID.\n",
    "    \n",
    "    Args:\n",
    "        user_id (int): The ID of the user for whom to get recommendations.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of the top recommended movie IDs for the given user.\n",
    "    \"\"\"\n",
    "    recs = recommendation.filter(col(\"userId\") == user_id).select(\"recommendations\")\n",
    "    recs = recs.select(explode(col(\"recommendations\")).alias(\"rec\")).select(\"rec.movieId\", \"rec.rating\")\n",
    "    item_list = recs.orderBy(col(\"rating\").desc()).select(\"movieId\").rdd.flatMap(lambda x: x).collect()\n",
    "    return item_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommendation for 100 users\n",
    "for i in range(1, 101):\n",
    "    result = get_recommendations(i)\n",
    "    print(f'Recommend movies for user {i}: ')\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
